%!TEX root = thesis.tex
\chapter{2-D Imaginary Time Evolving Block Decimation}
\label{chapter:2ditebd}

In one-dimensional many-body systems, the performance of one-dimension imaginary time evolving block decimation (1D-iTEBD) is very well, especially its high efficiency. Naturally, people want to extend the framework to study the two-dimensional systems. However, through many experiments we notice that the accuracy in 2-D is less than 1-D. In order to resolve that the obstacle, optimizations of 2-D algorithms became an essential part in condense matter physics. 

In the sections \ref{ite} and \ref{itebd}, we briefly review the idea of imaginary time evolution (TEBD) \cite{vidal_efficient_2003} \cite{vidal_efficient_2004} and explain how to extend it to simulate an infinite two-dimensional system (2D-iTEBD)\cite{li_efficient_2012}. However, the method recorded in ref.\cite{li_efficient_2012} is unstable because it need multiply too many pseudo-inverse matrices during updating the wave functions. Hence, In the sections \ref{2dhastin} and \ref{2dopt} we record more advance discussions about optimizing 2D-iTEBD, such as the method developed by Hastings \cite{}, combined with QR decomposition, and so on. In the final section \ref{Comparison}, we utilize 2D-iTEBD to simulate the toy models, Heisenberg and transverse Ising, on two-dimensional square lattice and compare the features among 2D-TEBD algorithms which are implemented by different way. Notice that in this chapter we just focus on obtaining good projected entangled pair states \cite{} by 2D-iTEBD. The optimization of measurement (accuracy) will be discussed in chapters \ref{chapter:ctm}.


\section{Imaginary Time Evolution}
\label{ite}
In the section, we apply the conclusion of the theory of imaginary time evolution and matrix product states (MPS) \cite{} to explain the fundamental concept of TEBD-like algorithms. Theoretically, if existing the imaginary time evolution operator $e^{-\tau H}$, where $H$ is the Hamiltonian of a specified model, we could project any initial random states to the ground state,
\begin{align}
	\label{mapgroud}
	\Ket{\psi_0} = \frac{e^{-\tau H} \Ket{\Psi}}{\parallel e^{-\tau H} \Ket{\Psi}\parallel}
\end{align}
However, according to eq.\ref{wavefunc}, we notice that the number of coefficients in an origin evolution operator $e^{-\tau H}$ is proportional to $d^N \times d^N$. In other words, it is impossible to update entire system directly. Therefor, in 1D quantum many-body systems we apply MPS structure to restrict the exponential increment of dimension. Base on the theory of the MPS, the wave function composed by pure states can be decompose to many unit cells by \textit{sigular value decomopostion} and \textit{Schmidt decomposition}. To explain the MPS structure more explicitly, we begin from splitting the wave function $\Ket{\Psi_N}$ [Fig. \ref{fig225}(a)] between $n$ and $n+1$ sites with Schmidt decomposition, 
\begin{align}
	\label{schmitwave}
	\Ket{\Psi_{N}} = \sum_{\alpha_n} \lambda_{\alpha_n} \Ket{\psi_{\alpha_n}^{[1\dots n]}} \Ket{\psi_{\alpha_n}^{[n+1\dots N]}}
\end{align}
where $\lambda_{\alpha_n} > 0$ and $\sum\limits_{\alpha+n}{\lambda_{\alpha_n}^2 = 1}$. To obtain the one site wave function $\Ket{\psi_{\alpha_n}^{[n+1]}}$, we perform Schmidt decomposition on $\Ket{\psi_{\alpha_n}^{[n+1\dots N]}}$ between the $n+1$ and $n+2$ sites,
\begin{align}
	\Ket{\psi_{\alpha_n}^{[n+1\dots N]}} = \sum_{\alpha_{n+1}} \lambda_{\alpha_{n+1}} \Ket{\psi_{\alpha_{n+1}}^{[n+1]}} \Ket{\psi_{\alpha_{n+2}}^{[n+2\dots N]}}
\end{align}
then span $\Ket{\psi_{\alpha_{n+1}}^{[n+1]}}$ by the spin basis $i_{n+1}$,
\begin{align}
	\Ket{\psi_{\alpha_{n+1}}^{[n+1]}} = \sum_{i_{n+1}}{\Gamma^{[n+1] i_{n+1}}_{\alpha_n \alpha_{n+1}} \Ket{i_{n+1}}}
\end{align}
and the Eq. \ref{schmitwave} can be re-written as, 
\begin{align}
	\Ket{\Psi_{N}} = \sum_{\alpha_n,\alpha_{n+1}}\sum_{i_{n+1}}{\lambda_{\alpha_n} \Gamma^{[n+1] i_{n+1}}_{\alpha_n \alpha_{n+1}} \lambda_{\alpha_{n+1}l} \Ket{\psi_{\alpha_n}^{[1\dots n]}} \Ket{i_{n+1}} \Ket{\psi_{\alpha_{n+2}}^{[n+2\dots N]}} }
\end{align}
In the end, we can perform the same process site-by-site in the entire system and obtain the MPS structure,
\begin{align}
	\Ket{\Psi_N} = \sum_{\alpha_1,\dots ,\alpha_N}\sum_{i_1,\dots ,i_N}{ \Gamma^{[1] i_{1}}_{\alpha_1} \lambda_{\alpha_1} \Gamma^{[2] i_{2}}_{\alpha_1 \alpha_{2}} \lambda_{\alpha_2} \dots  \lambda_{\alpha_{N-2}} \Gamma^{[N-1] i_{N-1}}_{\alpha_{N-2} \alpha_{N-1}} \lambda_{\alpha_{N-1}} \Gamma^{[N] i_{N}}_{\alpha_{N}} \Ket{i_1 i_2 \dots i_N}}
\end{align}
and the tensor network representation is shown as Fig. \ref{fig311}, 
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.90\textwidth]{figures/fig311.png}
	\caption[The tensor network representation of matrix product states]{The tensor network representation of matrix product states.}
	\label{fig311}
\end{figure}

Now that we try to expand it to a infinite chain \cite{}. Since the translation invariance, the wave function $\Ket{\Psi_{N=\infty}}$ can be represent as $n$-site translational symmetric states, which means that $\Gamma^{[i]}$ and $\lambda^{[i_{i}]}$ are independent of $\Gamma^{[i+n]}$ and $\lambda^{[i+n]}$. For instance, the tensor diagram can be drawn as Fig.\ref{fig312}, when $n=2$, which means that the wave function of a infinite chain can be recognized as a composite of matrix product states $\lambda^{[A]}\Gamma^{[A]}$ (red nodes) and $\lambda^{[B]}\Gamma^{[B]}$ (purple nodes).

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.90\textwidth]{figures/fig311.png}
	\caption[The tensor network representation of matrix product states]{The tensor network representation of matrix product states.}
	\label{fig312}
\end{figure}

Next, in order to update the two states in the unit cell, we utilize the \textit{Suzuki Trotter decomposition} to approximate the entire evolution operator with $2$-sites operators, \textit{The first-order Suzuk-Trotter decompostio} of operator $e^{\delta (A+B)}$ is,
\begin{align}
	\label{STd}
	e^{\delta A + B} = e^{\delta A}e^{\delta B} + O(\delta^2)
\end{align}
where $A$ and $B$ are two non-commutative operators.Therefor, we can approximate the entire evolution operator by grouping the two site operator $H_{AB}$ and $H_{BA}$,
\begin{align}
	\label{evoopt}
	e^{-\tau H} = \left(e^{-\delta H}\right)^{\frac{\tau}{\delta}} \approx \left(\prod e^{\delta H_{AB}} \right)\left( \prod e^{\delta H_{BA}}\right)
\end{align}
Therefor, we can obtain the evolution operator $e^{H_{AB}}$ and $e^{H_{BA}}$ straightly after solving two site $H_{AB}$ and $H_{BA}$.
So far, we have obtained the infinite MPS composed by 2-site unit cells and the 2-site evolution operators $e^{-\tau H_{AB}}$ and $e^{-\tau H_{BA}}$. Hence, the tensor network representation of Eq. \ref{mapgroud} can be drawn as Fig. \ref{fig313}, which means that the ground state $\Ket{\psi_0}$ can be regard as contracting all the tensors in the diagram. So the next problem: How can we contract them and preserve the structure like Fig{\ref{fig311}}?

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.90\textwidth]{figures/fig312.png}
	\caption[The picture of the main idea of itebd.]{The red and blue tensor denotes on \textit{odd} and \textit{even} sites. The yellow one are time evolution operators $e^{-\tau H_{k,k+1}}$ and $e^{-\tau H_{k+1,k}}$}
	\label{fig313}
\end{figure}
\section{Simple Infinite Imaginary-Time Evolving Block Decimation for 2-D system}

In this section, we focus on how to implement and optimize 2D-iTEBD algorithms and the more theoretical details are derived in the references \cite{vidal_classical_2007} \cite{jiang_accurate_2008} \cite{orus_infinite_2008}.
\label{itebd}
\subsection{One-dimensional iTEBD}
To resolve the problem in the end of the section \ref{ite}, the "Simple Update" scheme was developed and have widely applied to iPEPS \cite{} and PESS ansatz \cite{}. In order to explain it clearly, we start from a simple case, one-dimensional iTEBD. 

The tensor diagrams shown in the Fig. \ref{fig314} are the procedures of 1D-iTEBD which can be simply build by following steps,
\begin{enumerate}
		\item Initialization: According to Eq. \ref{mapgroud}, the ground state can be obtain from any random state $\Ket{\Psi}$ theoretically. Hence, we provide two rank-3 tensors $\Gamma^{[A]}$ and $\Gamma^{[B]}$ which dimension are $dD^2$, where $d$ is the dimension of physical basis and $D$ is the virtual bonds dimension, and two random diagonal matrix $\lambda^{[A]}$ and $\lambda^{[B]}$ which represent the entanglement between each sites at first. See Fig. \ref{fig314}(i).
		\item Obtain a cluster tensor $\theta$: As shown in Fig. \ref{fig314}(b),
			\begin{enumerate}
				\item Absorb the entangled matrices; 
					\begin{align}
						&\Gamma^{\prime [A]} = \sum_{ij}{\lambda^{[A]}_{i} \Gamma^{A}_{ij \sigma_i} \lambda^{[B]}_{j}} \\
						&\Gamma^{\prime [B]} = \sum_{k}{\Gamma^{B}_{k \sigma_j} \lambda^{[A]}_{k}}
					\end{align}
						\item Utilize the evolution operate $U(\tau)$: The 2-site evolution operator $U(\tau)$ can be simply obtained from Eq. \ref{evoopt}, In this case, 
							\begin{align}
								U(\tau) = e^{-\tau H_{AB}}
							\end{align}
			\end{enumerate}
		\item Decompose $\theta$ into the general form of the MPS:
		\item Truncation: See Fig. \ref{fig314}(iv), we notice that the dimension of bond $j$ increase to $dD$. To avoid the exponential increment of the dimension, the dimension of bond $j$ must be resized to $D$.
		\item Absorb the inverse entangled matrix $\lambda^{[A]}$: Remove the entangle influence from $\widetilde{\Gamma}^{[A]}$ and $\widetilde{\Gamma}^{[B]}$ and return the general form of the MPS, as shown in Fig. \ref{fig314}(v).
		\item Repeat the steps (2)-(5) to update the tensors $\widetilde{\Gamma}^{[B]}$, $\widetilde{\Gamma}^{[A]}$ and $\lambda^{[A]}$ with the evolution operator $e^{-\tau H_{BA}}$.
		\item Finally, iterate the steps (2)-(6) until the wave function converges.
In one dimensional many-body systems, the performance of iTEBD is pretty well. Although the accuracy is little less than DMRG \cite{}, it is still widely applied to study or test models due to its high efficiency.
\end{enumerate}

\begin{figure}[ht][b]
	\centering
	\includegraphics[width=0.90\textwidth]{figures/fig313.png}
	\caption[The tensor network diagrams for the 1-D iTEBD]{ (i)Absorb all $\lambda$ to $\Gamma$. (ii) Contract an evolution operator $e^{-\delta H}$ for evolving the system. (iii) Decompose the tensor $\theta$ by SVD. (iv) Truncate and Update the states and $\lambda$ on the green bond.(v) Remove $
		\lambda$ for obtaining the states. (iv) After updating the states and $\lambda$ on the purple bond, apply the way to update the red bond and repeat all the steps until the ground state convergence.}
	\label{fig314}
\end{figure}


In one dimensional many-body systems, the performance of iTEBD is pretty well. Although the accuracy is little less than DMRG \cite{}, it is still widely applied to study or test models due to its high efficiency.

\subsection{Two-dimensional iTEBD}
\label{2ditebd}

Due to the success in 1-D cases, we desire to extend the framework of iTEBD to simulate 2-D systems . In 2-D systems, we describe the wave functions by the projected entangled pair states (PEPS) rather than MPS. The PEPS structure is an naturally extension of MPS and obey the restriction of MPS. Therefore, it can be expanded to a infinite structure, iPEPS, which are composed by $n$-site translation invariance states. For instance, we can draw an tensor diagram as shown in Fig. \ref{fig315} to represent the wave function of a 2-D many-body system which is composed by 2-site translational symmetric states.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\textwidth]{figures/fig314.png}
	\caption[The tensor diagrams of 2-D lattice]{Four sites unit cell in iPEPS.}
	\label{fig315}
\end{figure}

After building the form of iPEPS, we start to deal with the problem of updating states. The most intuitive method is directional simple update, which means that the states of iPEPS must be updated by iTEBD along four directional moves, namely up, right, down and left. As shown in Fig.\ref{fig316}, 

\begin{enumerate}
		\item Initialization: According to Eq. \ref{mapgroud}, the ground state can be obtain from any random state $\Ket{\Psi}$ theoretically. Hence, we provide two rank-3 tensors $\Gamma^{[A]}$ and $\Gamma^{[B]}$ which dimension are $dD^2$, where $d$ is the dimension of physical basis and $D$ is the virtual bonds dimension, and two random diagonal matrix $\lambda^{[A]}$ and $\lambda^{[B]}$ which represent the entanglement between each sites at first. See Fig. \ref{fig314}(i).
		\item Obtain a cluster tensor $\theta$: As shown in Fig. \ref{fig314}(b),
			\begin{enumerate}
				\item Absorb the entangled matrices; 
					\begin{align}
						&\Gamma^{\prime [A]} = \sum_{ij}{\lambda^{[A]}_{i} \Gamma^{A}_{ij \sigma_i} \lambda^{[B]}_{j}} \\
						&\Gamma^{\prime [B]} = \sum_{k}{\Gamma^{B}_{k \sigma_j} \lambda^{[A]}_{k}}
					\end{align}
						\item Utilize the evolution operate $U(\tau)$: The 2-site evolution operator $U(\tau)$ can be simply obtained from Eq. \ref{evoopt}, In this case, 
							\begin{align}
								U(\tau) = e^{-\tau H_{AB}}
							\end{align}
			\end{enumerate}
		\item Decompose $\theta$ into the general form of the MPS:
		\item Truncation: See Fig. \ref{fig314}(iv), we notice that the dimension of bond $j$ increase to $dD$. To avoid the exponential increment of the dimension, the dimension of bond $j$ must be resized to $D$.
		\item Absorb the inverse entangled matrix $\lambda^{[A]}$: Remove the entangle influence from $\widetilde{\Gamma}^{[A]}$ and $\widetilde{\Gamma}^{[B]}$ and return the general form of the MPS, as shown in Fig. \ref{fig314}(v).
		\item Repeat the steps (2)-(5) to update the tensors $\widetilde{\Gamma}^{[B]}$, $\widetilde{\Gamma}^{[A]}$ and $\lambda^{[A]}$ with the evolution operator $e^{-\tau H_{BA}}$.
		\item Finally, iterate the steps (2)-(6) until the wave function converges.
			
In one dimensional many-body systems, the performance of iTEBD is pretty well. Although the accuracy is little less than DMRG \cite{}, it is still widely applied to study or test models due to its high efficiency.
\end{enumerate}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.80\textwidth]{figures/fig315.png}
	\caption[The tensor network diagrams of updating the green bond in iPEPS with 2D-iTEBD]{Absorb all $\lambda$ to $\Gamma$. (ii) Contract an evolution operator $e^{-\delta H}$ for evolving the system. (iii) Decompose the tensor $\theta$ by SVD. (iv) Truncate and Update the states and $\lambda$ on the green bond.(v) Remove $\lambda$ for obtaining the states. (iv) Obtain a original form of iPEPS. Repeat all the step to update the other bonds until the ground state energy convergence}
	\label{fig316}
\end{figure}

	\begin{figure}[ht]
	\centering
	\includegraphics[width=0.80\textwidth]{figures/fig316.png}
	\caption[The tensor network diagrams of updating the yellow bond in iPEPS with 2D-iTEBD]{Update the yellow bond and the steps are similar to Fig.\ref{fig315}}
	\label{fig316}
	\end{figure}

\section{Ameliorate two-dimensional iTEBD}
\label{2dhastin}

The directional simple update discussed in section.\ref{2ditebd} can obtain good iPEPS states in toy models. However, in some complicated model it becomes unstable and inefficient. The reason is that too many multiplications of pseudo-inverse $\lambda$ at the step Fig.\ref{fig315}(v). In numerical methods, it's dangerous to divide a value which is equal or approach to zero. In other words, the more inverse operations, the more probability of destroying algorithms and harder to converge. Hence, the scheme published by \textit{M. B. Hastings} \cite{hastings_light-cone_2009} was developed.

\begin{enumerate}
		\item Initialization: According to Eq. \ref{mapgroud}, the ground state can be obtain from any random state $\Ket{\Psi}$ theoretically. Hence, we provide two rank-3 tensors $\Gamma^{[A]}$ and $\Gamma^{[B]}$ which dimension are $dD^2$, where $d$ is the dimension of physical basis and $D$ is the virtual bonds dimension, and two random diagonal matrix $\lambda^{[A]}$ and $\lambda^{[B]}$ which represent the entanglement between each sites at first. See Fig. \ref{fig314}(i).
		\item Obtain a cluster tensor $\theta$: As shown in Fig. \ref{fig314}(b),
			\begin{enumerate}
				\item Absorb the entangled matrices; 
					\begin{align}
						&\Gamma^{\prime [A]} = \sum_{ij}{\lambda^{[A]}_{i} \Gamma^{A}_{ij \sigma_i} \lambda^{[B]}_{j}} \\
						&\Gamma^{\prime [B]} = \sum_{k}{\Gamma^{B}_{k \sigma_j} \lambda^{[A]}_{k}}
					\end{align}
						\item Utilize the evolution operate $U(\tau)$: The 2-site evolution operator $U(\tau)$ can be simply obtained from Eq. \ref{evoopt}, In this case, 
							\begin{align}
								U(\tau) = e^{-\tau H_{AB}}
							\end{align}
			\end{enumerate}
		\item Decompose $\theta$ into the general form of the MPS:
		\item Truncation: See Fig. \ref{fig314}(iv), we notice that the dimension of bond $j$ increase to $dD$. To avoid the exponential increment of the dimension, the dimension of bond $j$ must be resized to $D$.
		\item Absorb the inverse entangled matrix $\lambda^{[A]}$: Remove the entangle influence from $\widetilde{\Gamma}^{[A]}$ and $\widetilde{\Gamma}^{[B]}$ and return the general form of the MPS, as shown in Fig. \ref{fig314}(v).
		\item Repeat the steps (2)-(5) to update the tensors $\widetilde{\Gamma}^{[B]}$, $\widetilde{\Gamma}^{[A]}$ and $\lambda^{[A]}$ with the evolution operator $e^{-\tau H_{BA}}$.
		\item Finally, iterate the steps (2)-(6) until the wave function converges.
In one dimensional many-body systems, the performance of iTEBD is pretty well. Although the accuracy is little less than DMRG \cite{}, it is still widely applied to study or test models due to its high efficiency.
\end{enumerate}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1.00\textwidth]{figures/fig317.png}
	\caption[The tensor network diagrams for the 2-D iTEBD with QR decomposition]{The tensor network diagrams for the ameliorated 2-D iTEBD.}
	\label{fig317}
\end{figure}

\section{Optimizations}
\label{2dopt}

\subsection{Initialization}
\label{2doptInit}
Intuitively, the initialization of states should not affect the result. However, it's a serious misunderstanding. Actually, stating from a awful initial sates may break the algorithms or hardly converge.

From the viewpoint of physics, translational invariance is one of essential properties in many-body system, So we can assume that the group state on two sites should be similar. For instance, if the TN diagram of the states is shown as Fig \ref{fig321}(i), Fig \ref{fig321}(ii) might be the better way to initialize the states.

\begin{figure}[ht]
	\centering
	\includegraphics[width=1.00\textwidth]{figures/fig321.png}
	\caption[The diagrams of initializing projected entangled pair states]{(i) The structure of PEPS, (ii) The initialization of states}
	\label{fig321}
\end{figure}

\subsection{Truncattion Error}

\subsection{QR decomposition}

Though the strategy described in previous sections improve the stability, it's not efficient enough. The reason why is that the dimension of tensor $\theta$, in Fig.\ref{fig315}(iii) and Fig.\ref{fig317}(iii), is proportional to $d^2D^6$. In addition to that, the time complexity of singular value decomposition is proportional to $O(NM^2)$. In conclusion, those steps are expensive and the dimension of tensor $\theta$ must be redued for accelerating. 
\label{2doptQR} \begin{figure}[H] \centering \includegraphics[width=0.80\textwidth]{figures/fig318.png} \caption[The tensor network diagrams for the ameliorated 2-D iTEBD with QR decompositiont]{The tensor network diagrams for the ameliorated 2-D iTEBD.} \label{fig318} \end{figure} To achieve the goal, the projected pair state must be decomposed by QR decomposition \cite{li_efficient_2012} \cite{yang_accelerated_2007}. The processes making \textit{Simple Update} more efficient is illustrated in Fig \ref{fig318}.  Most of the steps shown in Fig \ref{fig318} are like in Fig \ref{fig315}. The only difference is that after absorbing all the $\lambda$, we decompose the state to an orthogonal matrix and an upper triangular matrix by QR. For instance, in Fig \ref{fig318} (ii), the state $A$ is decomposed to an orthogonal matrix X and upper triangular matrix $a_R$. Due to the columns of $X$ are orthonormal, $XX^{\dagger}$ is equal to $I$. In the other word, the tensor $X$ can be ignored and we just need consider the tensor $a_R$ by QR. Similarity, the state $B$ can be decomposed to a lower triangular $b_L$ and an orthogonal matrix $Y$ by LQ which is equivalence to operate QR decomposition after transpose the matrix. Next, (iii) we can obtain the tensor $\theta$ whose dimension is $d^2D$ from $a_R$, $b_L$ and an evolution operator.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.90\textwidth]{figures/fig319.png}
	\includegraphics[width=0.90\textwidth]{figures/fig320.png}
	\caption[The tensor network diagrams for the ameliorated 2-D iTEBD with QR decompositiont]{The tensor network diagrams for the ameliorated 2-D iTEBD.}
	\label{fig319}
\end{figure}

The strategy to accelerate \textit{Ameliorate Simple Update} is shown in the Fig \ref{fig319} and its main idea is also to reduce the dimension of $\theta$.

\section{Comparison}

So far, we have benchmarked the improved iTEBD. 

\label{Comparison}
\subsection{Different Initializations}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1.00\textwidth]{figures/fig322.png}
	\caption[Different methods to initialize the states]{(i) Type 1, (ii) Type 2}
	\label{fig322}
\end{figure}

See Fig \ref{fig323}, the both cases are 

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/fig323.png}
	\caption[Comparison the results of Heisenberg model on square lattice which are obtaining from different initial states.]{The Blue line represents updating tensors from the initial state shown in Fig \ref{fig322} (i) and the green one represents updating from Fig \ref{fig322} (ii)}
	\label{fig323}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/fig324.png}
	\caption[CPU times of different 2D-iTEBD with fixed trucation error]{}
	\label{fig324}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/fig325.png}
	\caption[Per epoch energy of Heisenberg model on 2d square lattice with fixed truncation error]{}
	\label{fig325}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/fig326.png}
	\caption[CPU times of different 2D-iTEBD with dynamic trucation error]{}
	\label{fig326}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/fig327.png}
	\caption[Per epoch energy of Heisenberg model on 2d square lattice with dynamic truncation error]{}
	\label{fig327}
\end{figure}
